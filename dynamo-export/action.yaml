name: Dynamo Export to S3
description: Export a DynamoDB Table to S3

inputs:
  source:
    description: The Source Environment of the Table
    required: true
  dynamo-table:
    description: The DynamoDB Table name to be Exported
    required: true
  s3-key:
    description: The S3 Key to use for the Backup
    default: dynamodb-extract
  enable-backups:
    description: Should Backups be enabled once complete
    default: "true"

runs:
  using: composite
  steps:

    - name: Export Table
      shell: bash
      env:
        source: ${{ inputs.source }}
        table: ${{ inputs.dynamo-table }}
        s3-bucket: cvs-${{ env.source }}-tf-data
        s3-key: ${{ inputs.s3-key }}
      run: |
        # Create Table Backup
        account=$(aws sts get-caller-identity --query "Account" --output text)
        printf "# \033[0;34mEnable Point In Time Recovery (PITR) on \033[0m${{ inputs.dynamo-table }}\n"
        aws dynamodb update-continuous-backups --table-name "${{ inputs.dynamo-table }}" --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true
        
        printf "# \033[0;34mExport \033[0m${{ inputs.dynamo-table }} \033[0;34mto \033[0ms3://${{ env.s3-bucket }}/${{ env.s3-key }}/${{ inputs.dynamo-table }}/$(date '+%Y')/$(date '+%-m')/$(date '+%-d')\n"
        aws dynamodb export-table-to-point-in-time --table-arn "arn:aws:dynamodb:eu-west-1:${account}:table/${{ inputs.dynamo-table }}" --s3-bucket ${{ env.s3-bucket }} --s3-prefix ${{ env.s3-key }}/${{ inputs.dynamo-table }}/$(date '+%Y')/$(date '+%-m')/$(date '+%-d') --export-format DYNAMODB_JSON --s3-sse-algorithm AES256
        
        if [[ "${{ inputs.enable-backups }}" == "false" ]]; then
          printf "# \033[0;34mDisable Point In Time Recovery (PITR) on \033[0m${{ inputs.dynamo-table }}\n"
          aws dynamodb update-continuous-backups --table-name "${{ inputs.dynamo-table }}" --point-in-time-recovery-specification PointInTimeRecoveryEnabled=${{ inputs.enable-backups }}
        fi